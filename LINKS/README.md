## How to:


### How to Use ROS 2 Lifecycle Nodes
Better manage the behavior of your ROS 2 system with lifecycle nodes

https://foxglove.dev/blog/how-to-use-ros2-lifecycle-nodes

________


### automaticaddison
https://automaticaddison.com/

### Sensor Fusion Using the Robot Localization Package – ROS 2
https://automaticaddison.com/sensor-fusion-using-the-robot-localization-package-ros-2/
not work - galactic


### The Ultimate Guide to the ROS 2 Navigation Stack – Foxy
https://automaticaddison.com/the-ultimate-guide-to-the-ros-2-navigation-stack/


### How to Publish Wheel Encoder Tick Data Using ROS 1 and Arduino
https://automaticaddison.com/how-to-publish-wheel-encoder-tick-data-using-ros-and-arduino/


_______________

###  Self-Driving Cars with ROS and Autoware

https://github.com/t-thanh/autoware2020-course/tree/master

hosted by Apex.AI​

Self-driving cars will transform the way we travel and commute. This technology merges robotics, machine learning, engineering, and modern software development methods.


https://www.apex.ai/autoware-course

_______________

### ndt_omp

https://github.com/dfki-ric/pclomp

Multi-threaded and SSE friendly NDT algorithm

This package provides an OpenMP-boosted Normal Distributions Transform (and GICP) algorithm derived from pcl. The NDT algorithm is modified to be SSE-friendly and multi-threaded. It can run up to 10 times faster than its original version in pcl.

_______________


### ndt_omp

https://github.com/koide3/ndt_omp

Multi-threaded and SSE friendly NDT algorithm

This package provides an OpenMP-boosted Normal Distributions Transform (and GICP) algorithm derived from pcl. The NDT algorithm is modified to be SSE-friendly and multi-threaded. It can run up to 10 times faster than its original version in pcl.

For using this package in non-ROS1 projects (ROS2 or without ROS), see forked repositories: dfki-ric/pclomp tier4/ndt_omp.

_______________

### NDT-based localization
https://habr.com/ru/articles/901300/

_______________


https://github.com/automaticaddison/mycobot_ros2/tree/jazzy

### mycobot_ros2
OS ROS_2

This repository contains ROS 2 packages for simulating and controlling the myCobot robotic arm using ROS 2 Control and MoveIt 2. It provides support for Gazebo simulation and visualization in RViz. Gazebo simulation also includes simulated 3D point cloud data from the depth camera (RGBD) sensor plugin for vision.

_______________



### Navigation Plugins

https://docs.nav2.org/plugins/index.html


There are a number of plugin interfaces for users to create their own custom applications or algorithms with. Namely, the costmap layer, planner, controller, behavior tree, and behavior plugins. A list of all known plugins are listed here below for ROS 2 Navigation. If you know of a plugin, or you have created a new plugin, please consider submitting a pull request with that information.

This file can be found and edited under sphinx_docs/plugins/index.rst. For tutorials on creating your own plugins, please see Writing a New Costmap2D Plugin, Writing a New Behavior Tree Plugin, Writing a New Controller Plugin, Writing a New Planner Plugin, Writing a New Behavior Plugin, or Writing a New Navigator Plugin.

_______________

### Spatio-Temporal Voxel Layer

https://github.com/SteveMacenski/spatio_temporal_voxel_layer/tree/humble

This is a drop in replacement for the voxel_grid voxel representation of the environment. This package does a number of things to improve on the voxel grid package and extend the capabilities offered to the users, under a LGPL v2.1 license. Developed and maintained by Steven Macenski at Simbe Robotics.


_________


### ROS2 CAN Package

https://docs.odriverobotics.com/v/latest/guides/ros-package.html
_________


### mecanum_drive — Mecanum-Drive Controller

This package implements ROS nodes to control and monitor a mecanum-drive robot.


https://gitlab.control.lth.se/robotlab/mecanum_drive

______________

### mecanum_drive — Mecanum-Drive Controller

This package implements ROS nodes to control and monitor a mecanum-drive robot.

https://github.com/dudasdavid/mecanum_drive
________


### ros2_control_demo_example_17

https://control.ros.org/humble/doc/ros2_controllers/mecanum_drive_controller/doc/userdoc.html

https://github.com/Juliaj/ros2_control_demos/tree/async_controller/example_17



MecanumWheelBot uses

In this example, we illustrate key concepts of the ros2_control framework, particularly the controller manager, asynchronous controllers, and asynchronous hardware interfaces. MecanumWheelBot is a simple mobile base using 4 mecanum wheels.

Find the documentation in doc/userdoc.rst or on control.ros.org.

________

### yahboom_rosmaster
ROS_2 

Automatic Addison support for the ROSMASTER X3 mecanum wheel robot robot by Yahboom - ROS 2

https://github.com/automaticaddison/yahboom_rosmaster



______

### ROS2 Package for ODrive

https://github.com/nguyen-v/ros_odrive_gim6010-8

This repository contains ROS2 packages for the ODrive motor controller:


______

### whisper_ros

https://github.com/mgonzs13/whisper_ros?tab=readme-ov-file#usage

This repository provides a set of ROS 2 packages to integrate whisper.cpp into ROS 2 using audio_common 4.0.5. Besides, silero-vad is used to perform VAD (Voice Activity Detection).

______

### llama_ros

https://github.com/mgonzs13/llama_ros?tab=readme-ov-file#llava_ros


This repository provides a set of ROS 2 packages to integrate llama.cpp into ROS 2. Using the llama_ros packages, you can easily incorporate the powerful optimization capabilities of llama.cpp into your ROS 2 projects by running GGUF-based LLMs and VLMs. You can also use features from llama.cpp such as GBNF grammars and modify LoRAs in real-time.

______

### MERLIN 2 (MachinEd Ros 2 pLanINg) for ROS 2

MERLIN 2 (MachinEd Ros pLanINg)

https://github.com/MERLIN2-ARCH/merlin2

The creation of a new action is presented in this section. This way, navigation action is presented in PDDL, MERLIN2 and MERLIN2 state machine.

NAVIGATION
TTS
STT


______


### mgonzs13 Miguel Ángel González Santamarta
https://github.com/mgonzs13

Ph.D. at Universidad de León. Research in Robotics and Artificial Intelligence.
______

### YASMIN (Yet Another State MachINe)

YASMIN is a project focused on implementing robot behaviors using Finite State Machines (FSM). It is available for ROS 2, Python and C++.


https://github.com/uleroboticsgroup/yasmin


______


### yolo_ros

https://github.com/mgonzs13/yolo_ros?tab=readme-ov-file

ROS 2 wrap for YOLO models from Ultralytics to perform object detection and tracking, instance segmentation, human pose estimation and Oriented Bounding Box (OBB). There are also 3D versions of object detection, including instance segmentation, and human pose estimation based on depth images.


______


### DetectorNode
ROS 2 interface to darknet, an open source neural network library.

This node can run object detectors like YOLO v3 or YOLO v7 on images and video streams.

https://github.com/ros2/openrobotics_darknet_ros


______


### n8n - Secure Workflow Automation for Technical Teams

Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.

https://github.com/n8n-io/n8n


______

### Autoware - the world's leading open-source software project for autonomous driving

https://github.com/autowarefoundation/autoware


______

### Jetson Zoo

https://elinux.org/Jetson_Zoo

This page contains instructions for installing various open source add-on packages and frameworks on NVIDIA Jetson, in addition to a collection of DNN models for inferencing.

______


https://silenceoverflow.github.io/Awesome-SLAM/

A curated list of SLAM resources


______

https://bluebotics.com/vda-5050-explained-agv-communication-standard/

WHAT IS VDA 5050?
VDA 5050 is a standardized interface for AGV communication. Specifically, this standard concerns the communication between AGVs (often called Fahrerloser Transportsysteme/Transportfahrzeuge (FTS) in Germany) and a master control (in other words, a fleet management software program).


_____

https://turtlebot.github.io/turtlebot4-user-manual/tutorials/turtlebot4_navigator.html

The TurtleBot 4 Navigator is a Python node that adds on to the Nav2 Simple Commander. It includes TurtleBot 4 specific features such as docking and undocking, as well as easy to use methods for navigating.

The TurtleBot 4 is a ROS 2-based mobile robot intended for education and research. The TurtleBot 4 is capable of mapping the robot's surroundings, navigating autonomously, running AI models on its camera, and more.

It uses a Create® 3 as the base platform, and builds on it with the TurtleBot 4 shell and User Interface (UI) board. Inside the shell sits a Raspberry Pi 4B which runs the TurtleBot 4 software.


Large Language Model Integration
This example demonstrates an integration between the OpenAI Chat Completions API and the Turtlebot 4, substantially inspired by the ‘Code as Policies: Language Model Programs for Embodied Control' (Liang et al.) research.

It demonstrates how an Large Language Model (LLM) can be ‘taught' how to use the Turtlebot 4 Navigation API with only a few examples, and also shows how an LLM can easily bridge natural language commands to API calls without an intermediate parsing step.

Before using this as the basis for a product, please consult the substantial list of caveats found in the original paper! :smile:



_______

https://en-m-wikipedia-org.translate.goog/wiki/Scott_Hassan?_x_tr_sl=en&_x_tr_tl=ru&_x_tr_hl=ru&_x_tr_pto=wapp

https://en-m-wikipedia-org.translate.goog/wiki/Willow_Garage?_x_tr_sl=en&_x_tr_tl=ru&_x_tr_hl=ru&_x_tr_pto=wapp

https://en-m-wikipedia-org.translate.goog/wiki/Clearpath_Robotics?_x_tr_sl=en&_x_tr_tl=ru&_x_tr_hl=ru&_x_tr_pto=wapp

Clearpath Robotics, Inc. (also known as Clearpath) was founded in 2009 by a group of four University of Waterloo graduates, and remains headquartered in Waterloo Region, Canada. The original goal of Clearpath was to streamline field robotics research for universities and private corporations, but the company has since expanded and is now also manufacturing and selling the OTTO line of self-driving vehicles for industrial environments.


_______


https://www.open3d.org/docs/release/tutorial/geometry/pointcloud.html


This tutorial demonstrates basic usage of a point cloud.

Visualize point cloud
The first part of the tutorial reads a point cloud and visualizes it.

______



https://theairlab.org/tartanslamseries/

The goal of this series is to expand the understanding of those both new and experienced with SLAM. Sessions will include research talks, as well as introductions to various themes of SLAM and thought provoking open-ended discussions. This is the inaugural series in the lineup of events aiming to foster fun, provocative discussions on robotics.

You can add the schedule to your Google calendar here or iCal here.

_______

https://github.com/hello-robot

https://hello-robot.com/stretch-3-product

Leverage the Power of ROS 2

A Pure Python Experience

https://github.com/hello-robot/stretch_body


___


https://forums.developer.nvidia.com/t/development-of-a-meccannum-wheel-robot-using-ros2-nav2/230687

Development of a Meccannum wheel robot using ROS2 NAV2
___

https://github.com/Ekumen-OS/andino/tree/humble

Andino is a fully open-source diff drive robot designed for educational purposes and low-cost applications. It is fully integrated with ROS 2 and it is a great base platform to improve skills over the robotics field. With its open-source design, anyone can modify and customize the robot to suit their specific needs.

___

https://github.com/Muhamedli/MEPhI_ROS2_drone
___

https://github.com/linorobot/linorobot2

linorobot2 is a ROS2 implementation of the linorobot package for building custom robots with 2WD, 4WD, or Mecanum drive configurations. This package provides launch files for Nav2 integration and includes a complete simulation pipeline in Gazebo.

The software stack integrated in this package is hardware agnosticso users can switch between booting up the physical robot and spawning the virtual robot in Gazebo.

___


https://github.com/mich-pest/ros2_navigation_stvl

Navigation and 3D Mapping with ROS2
University of Genoa A.Y. 2022/23, MSc Robotics Engineering

This package aims at analysing the functionalities provided by ROS2 Navigation2 combined with the Spatio-Temporal Voxel Layer (STVL) plugin for sensor fusion and mapping.
The whole package is based on Linorobot2 Package. This software component has been developed by the following contributors:

___

https://habr.com/ru/articles/751626/

1 авг 2023 в 14:14
AI доступный каждому разработчику
___


https://github.com/iit-DLSLab/Panoptic-SLAM

Panoptic-SLAM: Visual SLAM in Dynamic Environments using Panoptic Segmentation
This work presents Panoptic-SLAM, a visual SLAM system robust to dynamic environments, even in the presence of unknown objects. It uses panoptic segmentation to filter dynamic objects from the scene during the state estimation process. Panoptic-SLAM is based on ORB-SLAM3, a state-of-the-art SLAM system for static environments.

_____

https://huggingface.co/coqui/XTTS-v2

ⓍTTS is a Voice generation model that lets you clone voices into different languages by using just a quick 6-second audio clip. There is no need for an excessive amount of training data that spans countless hours.


__
https://github.com/coqui-ai/TTS

TTS is a library for advanced Text-to-Speech generation.

🚀 Pretrained models in +1100 languages.

🛠️ Tools for training new models and fine-tuning existing models in any language.

📚 Utilities for dataset analysis and curation.

__

https://github.com/NVIDIA-AI-IOT/whisper_trt?tab=readme-ov-file

WhisperTRT
This project optimizes OpenAI Whisper with NVIDIA TensorRT.

When executing the base.en model on NVIDIA Jetson Orin Nano, WhisperTRT runs ~3x faster while consuming only ~60% the memory compared with PyTorch.

WhisperTRT roughly mimics the API of the original Whisper model, making it easy to use.

______

https://github.com/ethz-asl/voxblox?tab=readme-ov-file
https://voxblox.readthedocs.io/en/latest/index.html

Voxblox is a volumetric mapping library based mainly on Truncated Signed Distance Fields (TSDFs). It varies from other SDF libraries in the following ways:

CPU-only, can be run single-threaded or multi-threaded for some integrators
Support for multiple different layer types (containing different types of voxels)
Serialization using protobufs
Different ways of handling weighting during merging
Different ways of inserting pose information about scans
Tight ROS integration (in voxblox_ros package)
Easily extensible with whatever integrators you want
Features an implementation of building Euclidean Signed Distance Fields (ESDFs, EDTs) directly from TSDFs.

____


https://github.com/onera/olcmr


Lidar-based Online Localisation and Colored Mesh Reconstruction ROS2/ROS1 Architecture
This repository contains a hybrid ROS2/ROS1 architecture for LiDAR based SLAM and real-time 3D colored mesh reconstruction using TSDF for ground exploration robots.

_______


https://github.com/naumovan/basicRL_workshop/tree/main

Воркшоп по базовому Reinforcement Learning (RL)
Добро пожаловать в репозиторий, посвящённый воркшопу по основам Reinforcement Learning (RL)! Здесь вы познакомитесь с ключевыми концепциями RL и получите практический опыт обучения RL-агента на примере Huggy.

